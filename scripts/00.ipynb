{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26133,"status":"ok","timestamp":1671048765062,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"},"user_tz":360},"id":"e3HytLQt-3G1","outputId":"02fc49a1-b274-4227-b607-99c8b2a2171b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jKF-p4HH_Cbo","executionInfo":{"status":"ok","timestamp":1671049239386,"user_tz":360,"elapsed":470,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Projects/reddit-vote-predictor')\n","import sys\n","import pandas as pd\n","from datetime import datetime\n","# Import custom module\n","from scripts.RedditScrape import * # imports a class `RedditScrape`"]},{"cell_type":"code","source":["# Reddit's own api:\n","!pip3 install psaw\n","!pip3 install praw\n","import psaw\n","import praw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-p-tfQaGg8r","executionInfo":{"status":"ok","timestamp":1671048793390,"user_tz":360,"elapsed":9108,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"920c3595-02dd-4c3b-bb8c-2c9546a2795a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting psaw\n","  Downloading psaw-0.1.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from psaw) (2.23.0)\n","Requirement already satisfied: Click in /usr/local/lib/python3.8/dist-packages (from psaw) (7.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->psaw) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->psaw) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->psaw) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->psaw) (2.10)\n","Installing collected packages: psaw\n","Successfully installed psaw-0.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting praw\n","  Downloading praw-7.6.1-py3-none-any.whl (188 kB)\n","\u001b[K     |████████████████████████████████| 188 kB 4.8 MB/s \n","\u001b[?25hCollecting update-checker>=0.18\n","  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n","Collecting websocket-client>=0.54.0\n","  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n","\u001b[?25hCollecting prawcore<3,>=2.1\n","  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from prawcore<3,>=2.1->praw) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.9.24)\n","Installing collected packages: websocket-client, update-checker, prawcore, praw\n","Successfully installed praw-7.6.1 prawcore-2.3.0 update-checker-0.18.0 websocket-client-1.4.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1JiHU41_VP_"},"outputs":[],"source":["# Set date range from which to extract data for two subreddits\n","# NOTE: ater running the data scraping and cleaning pipeline, one year of data\n","# resulted in around 1000 images, so we'll add time to the date range\n","# 10 years from the start of 2011 to the end of 2020\n","start_ = datetime(2011, 1, 1)\n","end_ = datetime(2020, 12, 31)\n","# Run the scraping pipeline using custom RedditScrape class imported above\n","cat = RedditScrape('cat', start_, end_)\n","cat.scrape_posts()\n","cat.posts.to_csv('data/tbl/cat_posts.csv', index=False)\n","dog = RedditScrape('dog', start_, end_)\n","dog.scrape_posts()\n","dog.posts.to_csv('data/tbl/dog_posts.csv', index=False)"]},{"cell_type":"code","source":["# If the above is not run, read in the data\n","cat = pd.read_csv('data/tbl/cat_posts.csv', index_col = None)\n","dog = pd.read_csv('data/tbl/dog_posts.csv', index_col = None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"822ygeALRX7k","executionInfo":{"status":"ok","timestamp":1671049247886,"user_tz":360,"elapsed":1635,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"d3629104-2a7c-448e-9e98-f5a41b50b290"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3,5) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"markdown","source":["## Using `PRAW`\n","Now use `praw` to fetch additional information about each post now that it has been efficiently scraped using `psaw`. This will help us gather more information that will help more accurately filter for good posts/images, and acquire information that might be useful in modeling `score`.\n","\n","Use the `id` field of the `psaw` results to get more information for each post."],"metadata":{"id":"KBG8O9zQjU4I"}},{"cell_type":"code","source":["# reddit = praw.Reddit(\n","#     client_id = 'client id',\n","#     client_secret = 'client secret',\n","#     username = 'username',\n","#     password = 'password',\n","#     user_agent = 'my user agent'\n","# )\n","# Fill in all fields above\n","# Docs: https://praw.readthedocs.io/en/stable/getting_started/quick_start.html\n","# Now simply lookup the scraped posts on reddit's praw using the id obtained by psaw\n","# Then use the following method to get more data for each post:\n","# post = reddit.submission(id = ID)\n","# where ID is the value in column \"id\" in the data obtained from psaw"],"metadata":{"id":"2oj2AkdPjnlH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The above arguments are saved in a secret json file."],"metadata":{"id":"2PT8nt_qhEM6"}},{"cell_type":"code","source":["import json\n","with open('reddit_args.json') as f:\n","  args = json.load(f)\n","# Now use the args (which is a dict of keyword arguments) to set up the instance\n","# of the reddit praw api Reddit class\n","reddit = praw.Reddit(**args)"],"metadata":{"id":"cOiDZiVQdUnw","executionInfo":{"status":"ok","timestamp":1671049261366,"user_tz":360,"elapsed":376,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Using each post in the data scraped using `psaw`, we search for the exact submission using the `reddit` object created above. Each submission has attributes:\n","\n","* `submission.score` # the score upvotes - downvotes\n","* `submission.ups` # the number of upvotes\n","* `submission.downs` # the number of downvotes\n"],"metadata":{"id":"DJLqaqZgrIiy"}},{"cell_type":"code","source":["cat.thumbnail"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoMRPJgomqVZ","executionInfo":{"status":"ok","timestamp":1671049272537,"user_tz":360,"elapsed":19,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"2c39d419-b37f-44ef-8051-d6da7dbeaa2d"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        https://b.thumbs.redditmedia.com/XbsSoHVRZJ-ia...\n","1        https://b.thumbs.redditmedia.com/0ysKTld1ll0fA...\n","2        https://b.thumbs.redditmedia.com/4VhoODZheXtqx...\n","3        https://b.thumbs.redditmedia.com/2FB2XyuoZ1sWf...\n","4        https://b.thumbs.redditmedia.com/cGTcHLpwYBO4R...\n","                               ...                        \n","50173                http://thumbs.reddit.com/t3_fhy5w.png\n","50174                http://thumbs.reddit.com/t3_fe3so.png\n","50175                                              default\n","50176                                              default\n","50177                                              default\n","Name: thumbnail, Length: 50178, dtype: object"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"6qhXbMFWTFr5"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}