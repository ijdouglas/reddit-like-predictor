{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22729,"status":"ok","timestamp":1691778030022,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"},"user_tz":300},"id":"e3HytLQt-3G1","outputId":"8cbc2872-643c-49bc-ce9f-68e568635668"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"UD04Uk8pF5U9","executionInfo":{"status":"ok","timestamp":1691778034526,"user_tz":300,"elapsed":380,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"jKF-p4HH_Cbo","executionInfo":{"status":"ok","timestamp":1691778039569,"user_tz":300,"elapsed":2168,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Projects/reddit-vote-predictor')\n","import sys\n","import pandas as pd\n","from datetime import datetime\n","# Import custom module\n","from scripts.RedditScrape import * # imports a class `RedditScrape`"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13601,"status":"ok","timestamp":1691778055431,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"},"user_tz":300},"id":"k-p-tfQaGg8r","outputId":"88e64af4-85a1-4604-d046-79f6eaba4122"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting psaw\n","  Downloading psaw-0.1.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from psaw) (2.31.0)\n","Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from psaw) (8.1.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->psaw) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->psaw) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->psaw) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->psaw) (2023.7.22)\n","Installing collected packages: psaw\n","Successfully installed psaw-0.1.0\n","Collecting praw\n","  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n","  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n","Collecting update-checker>=0.18 (from praw)\n","  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.6.1)\n","Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n","Installing collected packages: update-checker, prawcore, praw\n","Successfully installed praw-7.7.1 prawcore-2.3.0 update-checker-0.18.0\n"]}],"source":["# Reddit's own api:\n","!pip3 install psaw\n","!pip3 install praw\n","import psaw\n","import praw"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"p1JiHU41_VP_","colab":{"base_uri":"https://localhost:8080/","height":397},"executionInfo":{"status":"error","timestamp":1691778447513,"user_tz":300,"elapsed":390212,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"aa5b42de-7cc1-4a05-bfab-d9fa9c6ce6bf"},"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-aa932a16e234>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mend_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run the scraping pipeline using custom RedditScrape class imported above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRedditScrape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/tbl/cat_posts.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Projects/reddit-vote-predictor/scripts/RedditScrape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, subreddit_name, start_epoch, end_epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpsaw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPushshiftAPI\u001b[0m \u001b[0;31m# usually has to be installed on Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Define attributes (also called instance variables)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPushshiftAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubreddit_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubreddit_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, r, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mshards_down_behavior\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_retries, max_sleep, backoff, rate_limit_per_minute, max_results_per_request, detect_local_tz, utc_offset_secs, domain, https_proxy, shards_down_behavior)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrate_limit_per_minute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Connecting to /meta endpoint to learn rate limit.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mrate_limit_per_minute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'server_ratelimit_per_minute'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"server_ratelimit_per_minute: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrate_limit_per_minute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/psaw/PushshiftAPI.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, url, payload)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got non 200 code %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to connect to pushshift.io. Max retries exceeded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Unable to connect to pushshift.io. Max retries exceeded."]}],"source":["# Set date range from which to extract data for two subreddits\n","# NOTE: ater running the data scraping and cleaning pipeline, one year of data\n","# resulted in around 1000 images, so we'll add time to the date range\n","# 10 years from the start of 2011 to the end of 2020\n","start_ = datetime(2011, 1, 1)\n","end_ = datetime(2020, 12, 31)\n","# Run the scraping pipeline using custom RedditScrape class imported above\n","cat = RedditScrape('cat', start_, end_)\n","cat.scrape_posts()\n","cat.posts.to_csv('data/tbl/cat_posts.csv', index=False)\n","dog = RedditScrape('dog', start_, end_)\n","dog.scrape_posts()\n","dog.posts.to_csv('data/tbl/dog_posts.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"822ygeALRX7k"},"outputs":[],"source":["# If the above is not run, read in the data\n","cat = pd.read_csv('data/tbl/cat_posts.csv', index_col = None)\n","dog = pd.read_csv('data/tbl/dog_posts.csv', index_col = None)"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}