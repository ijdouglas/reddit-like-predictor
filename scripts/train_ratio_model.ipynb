{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwA1VJIx2a_y","executionInfo":{"status":"ok","timestamp":1693668577606,"user_tz":300,"elapsed":18802,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"ca1a3aed-12f8-44ff-8fbb-2c1c20187753"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"jKF-p4HH_Cbo","executionInfo":{"status":"ok","timestamp":1693668584332,"user_tz":300,"elapsed":6730,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","import os\n","os.chdir('/content/drive/My Drive/Projects/reddit-vote-predictor')\n","import multiprocessing as mp\n","import sys\n","import shutil as sh\n","import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","import datetime as dt\n","import matplotlib.pyplot as plt\n","from scipy import stats as s\n","from skimage import io\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import datetime as dt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models\n","# For object detection model:\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from PIL import Image, ImageDraw\n","# For loading images from URL:\n","import requests\n","from io import BytesIO\n","from tqdm import tqdm"]},{"cell_type":"code","source":["print(torch.cuda.is_available())  # Should print True\n","print(torch.cuda.get_device_name(0))  # Prints the GPU name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RM_qTCFf2uqg","executionInfo":{"status":"ok","timestamp":1693668584333,"user_tz":300,"elapsed":14,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"071a87a1-c972-44a0-8894-c87a8040a499"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","Tesla T4\n"]}]},{"cell_type":"markdown","source":["#### Read in data\n","\n","The previous scripts did the following\n","1. Scrape posts from a given subreddit (in this case r/dog and r/cat) within a given time frame\n","2. Delete posts not containing an image as the `post_hint`\n","3. Then use Reddit's API to pull additional data, such as `upvote_ratio`\n","4. Delete posts that have one upvote since this is indistinguishable from posts that received the default one upvote upon posting and nothing else.\n","5. Delete posts for which the URL links to an image that cannot be found\n","6. Delete posts for which an object-detection model cannot locate a dog (or cat).\n"],"metadata":{"id":"RP2lXLWU33gi"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"0r2Ze_HW2VnS","executionInfo":{"status":"ok","timestamp":1693668586148,"user_tz":300,"elapsed":1827,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51f261de-672d-459c-888c-2e3d39aba276"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2787, 29)\n","(4314, 29)\n"]}],"source":["dog = pd.read_csv('data/tbl/dog-final-data_upvote-ratio-model.csv', index_col = None)\n","cat = pd.read_csv('data/tbl/cat-final-data_upvote-ratio-model.csv', index_col = None)\n","# Make sure x and y are int\n","dog[['x', 'y']] = dog[['x', 'y']].applymap(int)\n","cat[['x', 'y']] = cat[['x', 'y']].applymap(int)\n","print(dog.shape)\n","print(cat.shape)"]},{"cell_type":"markdown","metadata":{"id":"tMpWPWbJ2VnV"},"source":["## Upvote Ratio Model Training\n"]},{"cell_type":"markdown","source":["#### Preprocessing via Dataloader\n","\n","1. Load image from URL\n","2. Check color format and convert to RGB if necessary\n","3. Crop size 224 from the center of the bounding box (if not possible obtain same size area from the border of image)\n","4. Resize to 224, 224\n","5. Convert to tensor"],"metadata":{"id":"N8Rrr7b7z-Nh"}},{"cell_type":"code","source":["def download_img(url_):\n","  try:\n","    response = requests.get(url_)\n","    image = Image.open(BytesIO(response.content))\n","    return image\n","  except requests.RequestException:\n","    # Handle network errors here\n","    raise Exception(f\"Error downloading image from {url_}\")\n","\n","def ensure_RGB(image_):\n","  if image_.mode != 'RGB':\n","    image_ = image_.convert('RGB')\n","  return image_\n","\n","def crop_image(image_, x, y, output_size = (224, 224)):\n","  # Calculate the crop boundaries\n","  width, height = image_.size\n","  left = max(0, x - output_size[0] // 2)\n","  top = max(0, y - output_size[1] // 2)\n","  right = min(width, x + output_size[0] // 2)\n","  bottom = min(height, y + output_size[1] // 2)\n","  return image_.crop((left, top, right, bottom))\n","\n","\n","# The rest of the transformations use torch.transforms\n","torch_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])"],"metadata":{"id":"nZQjKJ6MnGxY","executionInfo":{"status":"ok","timestamp":1693668591001,"user_tz":300,"elapsed":246,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Custom Dataset using image URLs\n","class CustomUrlDataset(Dataset):\n","    def __init__(self, URLs, targets, crop_Xs, crop_Ys, transform = None):\n","        self.img_urls = URLs\n","        self.X = crop_Xs\n","        self.Y = crop_Ys\n","        self.targets = targets\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.img_urls)\n","\n","    def __getitem__(self, idx):\n","      # Get image-specific data\n","      img_url = self.img_urls[idx]\n","      x = self.X[idx]\n","      y = self.Y[idx]\n","      target = self.targets[idx]\n","\n","      # Download the image\n","      image = download_img(img_url)\n","\n","      # ensure color format is RGB\n","      image = ensure_RGB(image)\n","\n","      # Crop around the target object\n","      image = crop_image(image, x, y)\n","\n","      # Apply the pytorch transforms if supplied\n","      if self.transform:\n","          image = self.transform(image)\n","\n","      return image, target"],"metadata":{"id":"sM3t0524XAZU","executionInfo":{"status":"ok","timestamp":1693603101697,"user_tz":300,"elapsed":145,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import time\n","# Download all the images in advance to avoid unexpected connection errors\n","for i in tqdm(range(dog.shape[0])):\n","  _id_ = dog.id[i]\n","  _url_ = dog.FEATURE[i]\n","  try:\n","    _resp_ = requests.get(_url_)\n","    _img_ = Image.open(BytesIO(_resp_.content))\n","    _img_ = ensure_RGB(_img_)\n","  except ConnectionResetError:\n","    time.sleep(5)\n","    # retry\n","    _resp_ = requests.get(_url_)\n","    _img_ = Image.open(BytesIO(_resp_.content))\n","    _img_ = ensure_RGB(_img_)\n","  _path_ = os.path.join('data/img/upvote_ratio_final/dog', str(_id_) + '.jpeg')\n","  # Ensure the save directory exists\n","  # Save the image as a JPG file\n","  _img_.save(_path_, \"JPEG\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9Bqv2tg0CfX","executionInfo":{"status":"ok","timestamp":1693594806543,"user_tz":300,"elapsed":1752090,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"b56f08c6-bc51-4f64-b920-94192664bd41"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2787/2787 [10:36<00:00,  4.38it/s]\n","100%|██████████| 4314/4314 [18:35<00:00,  3.87it/s]\n"]}]},{"cell_type":"code","source":["del _id_, _url_, _resp_, _img_, _path_\n","for i in tqdm(range(cat.shape[0])):\n","  _id_ = cat.id[i]\n","  _url_ = cat.FEATURE[i]\n","  try:\n","    _resp_ = requests.get(_url_)\n","    _img_ = Image.open(BytesIO(_resp_.content))\n","    _img_ = ensure_RGB(_img_)\n","  except ConnectionResetError:\n","    time.sleep(5)\n","    # retry\n","    _resp_ = requests.get(_url_)\n","    _img_ = Image.open(BytesIO(_resp_.content))\n","    _img_ = ensure_RGB(_img_)\n","  _path_ = os.path.join('data/img/upvote_ratio_final/cat', str(_id_) + '.jpeg')\n","  # Ensure the save directory exists\n","  # Save the image as a JPG file\n","  _img_.save(_path_, \"JPEG\")\n",""],"metadata":{"id":"8Ctbf0ndCDk_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_img(filename):\n","  return Image.open(filename)\n","\n","# Custom Dataset using image paths\n","class CustomImgDataset(Dataset):\n","  def __init__(self, image_directory, image_idx, targets, crop_Xs, crop_Ys, transform=None):\n","    # parse arguments\n","    self.img_dir = image_directory\n","    self.img_idx = image_idx\n","    self.X = crop_Xs\n","    self.Y = crop_Ys\n","    self.targets = targets\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return len(self.img_idx)\n","\n","  def __getitem__(self, idx):\n","    # Get image-specific data\n","    file_path = os.path.join(self.img_dir, str(self.img_idx[idx]) + '.jpeg')\n","    x = self.X[idx]\n","    y = self.Y[idx]\n","    target = self.targets[idx]\n","\n","    # Read the image from file\n","    image = read_img(file_path)\n","\n","    # Ensure color format is RGB\n","    image = ensure_RGB(image) # likely redundant but just to be safe.\n","\n","    # Crop around the target object\n","    image = crop_image(image, x, y)\n","\n","    # Apply the PyTorch transforms if supplied\n","    if self.transform:\n","        image = self.transform(image)\n","\n","    return image, target"],"metadata":{"id":"Ozd0fr5a0ir9","executionInfo":{"status":"ok","timestamp":1693668601433,"user_tz":300,"elapsed":564,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["#### Set model params for `r/dog`"],"metadata":{"id":"3278zeUHtCjo"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"RsF9c30RFisL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693603119618,"user_tz":300,"elapsed":3661,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"1cc3afde-d68b-4f9d-913f-725ce45e4ee8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["## Data setup ##\n","\n","data = dog # data frame (from global environment via pd.read_csv above)\n","FEATURE = 'FEATURE' # variable name of image url in data\n","TARGET = 'upvote_ratio' # variable name of target in data\n","#IMG_URL_VEC = data[FEATURE] # vector of feature url\n","IMG_DIR = 'data/img/upvote_ratio_final/dog'\n","IMG_ID_VEC = data['id']\n","TARGET_VEC = torch.tensor(data[TARGET].values, dtype=torch.float32) # target vector\n","X = data['x'] # vector of x coordinates of cropping center pixel\n","Y = data['y'] # vector of y coordinates of cropping center pixel\n","\n","#-----------#\n","\n","\n","## GPU setup ##\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","#-----------#\n","\n","\n","## Data Loaders ##\n","# USING IMAGE DIRECTORY METHOD\n","dataset = CustomImgDataset(IMG_DIR, IMG_ID_VEC, TARGET_VEC, X, Y, torch_transforms)\n","batch_size = 32\n","train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","#-----------#\n","\n","\n","## VGG-16 model ##\n","\n","# Get the pretrained model\n","model = models.vgg16(pretrained=True)\n","# Freeze the pretrained layers\n","for param in model.parameters():\n","    param.requires_grad = False\n","# Unfreeze and modify the last layer for regression\n","model.classifier[6] = nn.Linear(4096, 1)\n","# Move the model to the GPU if available\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","#-----------#\n","\n","\n","## Loss Function and Optimizer ##\n","\n","# Mean Squared Error (MSE) Loss\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","#-----------#\n"]},{"cell_type":"markdown","source":["#### Train the model"],"metadata":{"id":"M6ridCDzvSl3"}},{"cell_type":"code","source":["## Training Loop ##\n","\n","# Final parameter setup and logging\n","num_epochs = 100\n","#num_epochs = 1\n","print_every = 5\n","#print_every = 1\n","\n","#-----------#\n","\n","# Train the model\n","for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    for images, targets in train_loader:\n","        optimizer.zero_grad()\n","        images, targets = images.to(device), targets.to(device)  # Move data to GPU\n","        if images is None or targets is None:\n","          continue\n","        outputs = model(images)\n","        loss = criterion(outputs.squeeze(), targets)\n","        loss.backward()\n","        optimizer.step()\n","    #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","    if (epoch + 1) % print_every == 0:  # Print every 5 epochs\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","#-----------#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HA4ywsRhvLIT","executionInfo":{"status":"ok","timestamp":1693609454416,"user_tz":300,"elapsed":6322059,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"43489431-8d69-4798-9636-bc2bcb6df7d9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["  5%|▌         | 5/100 [05:33<1:44:52, 66.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/100], Loss: 0.0732\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 10/100 [10:50<1:35:13, 63.48s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/100], Loss: 0.0140\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 15/100 [16:01<1:28:19, 62.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/100], Loss: 0.0305\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 20/100 [21:23<1:25:36, 64.21s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/100], Loss: 0.1183\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 25/100 [26:38<1:18:41, 62.96s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [25/100], Loss: 0.2442\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 30/100 [31:54<1:13:26, 62.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [30/100], Loss: 0.0585\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 35/100 [37:07<1:08:33, 63.29s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [35/100], Loss: 0.0754\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 40/100 [42:33<1:04:37, 64.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [40/100], Loss: 0.1364\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 45/100 [47:55<58:42, 64.05s/it]  "]},{"output_type":"stream","name":"stdout","text":["Epoch [45/100], Loss: 0.2009\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 50/100 [53:09<52:31, 63.03s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [50/100], Loss: 0.0190\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▌    | 55/100 [58:22<46:45, 62.35s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [55/100], Loss: 0.0770\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 60/100 [1:03:37<42:14, 63.37s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [60/100], Loss: 0.0482\n"]},{"output_type":"stream","name":"stderr","text":[" 65%|██████▌   | 65/100 [1:09:03<37:47, 64.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [65/100], Loss: 0.0104\n"]},{"output_type":"stream","name":"stderr","text":[" 70%|███████   | 70/100 [1:14:19<31:37, 63.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [70/100], Loss: 0.1371\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▌  | 75/100 [1:19:33<26:08, 62.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [75/100], Loss: 0.0234\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 80/100 [1:24:36<20:15, 60.80s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [80/100], Loss: 0.0026\n"]},{"output_type":"stream","name":"stderr","text":[" 85%|████████▌ | 85/100 [1:29:46<15:33, 62.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [85/100], Loss: 0.1663\n"]},{"output_type":"stream","name":"stderr","text":[" 90%|█████████ | 90/100 [1:34:55<10:19, 61.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [90/100], Loss: 0.0439\n"]},{"output_type":"stream","name":"stderr","text":[" 95%|█████████▌| 95/100 [1:40:07<05:12, 62.50s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [95/100], Loss: 0.0202\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [1:45:21<00:00, 63.22s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [100/100], Loss: 0.0985\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"VhGkS_lGm39D"},"source":["Save model"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CexikTAKnqtD","executionInfo":{"status":"ok","timestamp":1693609455650,"user_tz":300,"elapsed":1248,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"outputs":[],"source":["torch.save(model.state_dict(), 'models/dog/vanilla_upvote_ratio_model.pth')"]},{"cell_type":"markdown","source":["#### Evaluate on a test image"],"metadata":{"id":"Wuq1YdsBvhYL"}},{"cell_type":"code","source":["# Use the test image of the golden retriever with the one ear\n","model.eval()\n","test_image_url = 'https://media.cnn.com/api/v1/images/stellar/prod/200313124810-02-rae-golden-retriever.jpg'\n","try:\n","    test_image = torch_transforms(ensure_RGB(download_img(test_image_url))).unsqueeze(0)\n","except requests.RequestException:\n","    raise Exception(f\"Error processing test image\")\n","\n","with torch.no_grad():\n","    test_image = test_image.to(device)  # Move test image to GPU\n","    predicted_target = model(test_image).item()\n","\n","print(f\"Predicted Target: {predicted_target:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i323H9wivgG8","executionInfo":{"status":"ok","timestamp":1693609455867,"user_tz":300,"elapsed":221,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"95a7b5d8-dad0-490e-f9d0-b5b96e6e8021"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Target: 0.6965\n"]}]},{"cell_type":"markdown","source":["### With r/cat (using a training and validation sample)"],"metadata":{"id":"SJWQXdw_RDj6"}},{"cell_type":"code","source":["## Data setup ##\n","batch_size = 32\n","train = cat.sample(frac=0.8) # 80% in train\n","test = cat.drop(train.index) # The other 20% in test\n","# The __getitem__ method in the dataloader gets data based on dataframe index\n","# so reset it here so that indices 0:shape[0] correspond to the data in order\n","train = train.reset_index(drop = True)\n","test = test.reset_index(drop = True)\n","FEATURE = 'FEATURE' # variable name of image url in data\n","TARGET = 'upvote_ratio' # variable name of target in data\n","#IMG_URL_VEC = data[FEATURE] # vector of feature url\n","IMG_DIR = 'data/img/upvote_ratio_final/cat'\n","# Train data:\n","IMG_ID_VEC_train = train['id']\n","TARGET_VEC_train = torch.tensor(train[TARGET].values, dtype=torch.float32) # target vector\n","X_train = train['x'] # vector of x coordinates of cropping center pixel\n","Y_train = train['y'] # vector of y coordinates of cropping center pixel\n","# Repeat for test\n","IMG_ID_VEC_test = test['id']\n","TARGET_VEC_test = torch.tensor(test[TARGET].values, dtype=torch.float32) # target vector\n","X_test = test['x'] # vector of x coordinates of cropping center pixel\n","Y_test = test['y']\n","\n","#-----------#\n","\n","\n","## GPU setup ##\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","#-----------#\n","\n","\n","## Data Loaders ##\n","# USING IMAGE DIRECTORY METHOD\n","train_dataset = CustomImgDataset(IMG_DIR, IMG_ID_VEC_train, TARGET_VEC_train, X_train, Y_train, torch_transforms)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","# Repeat for test\n","test_dataset = CustomImgDataset(IMG_DIR, IMG_ID_VEC_test, TARGET_VEC_test, X_test, Y_test, torch_transforms)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","#-----------#\n","\n","\n","## VGG-16 model ##\n","\n","# Get the pretrained model\n","model = models.vgg16(pretrained=True)\n","# Freeze the pretrained layers\n","for param in model.parameters():\n","    param.requires_grad = False\n","# Unfreeze and modify the last layer for regression\n","model.classifier[6] = nn.Linear(4096, 1)\n","# Move the model to the GPU if available\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","#-----------#\n","\n","\n","## Loss Function and Optimizer ##\n","\n","# Mean Squared Error (MSE) Loss\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","#-----------#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoJ18MsxcdoE","executionInfo":{"status":"ok","timestamp":1693668724098,"user_tz":300,"elapsed":1735,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"90e850ab-c5d4-4003-c242-3d91e536bf33"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"markdown","source":["#### Train r/cat model"],"metadata":{"id":"n7EqbZ75e3En"}},{"cell_type":"code","source":["## Training Loop ##\n","\n","# Final parameter setup and logging\n","num_epochs = 100\n","print_every = 5\n","#num_epochs = 1\n","#print_every = 1\n","\n","#-----------#\n","\n","# Train the model\n","for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    for images, targets in train_loader:\n","        optimizer.zero_grad()\n","        images, targets = images.to(device), targets.to(device)  # Move data to GPU\n","        if images is None or targets is None:\n","          continue\n","        outputs = model(images)\n","        loss = criterion(outputs.squeeze(), targets)\n","        loss.backward()\n","        optimizer.step()\n","    #print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","    if (epoch + 1) % print_every == 0:  # Print every 5 epochs\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n","\n","#-----------#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693670420000,"user_tz":300,"elapsed":1686048,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"5fbbb413-cfe6-4508-e81a-f29fbcf03a06","id":"dlURntaae-0S"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [28:05<00:00, 1685.78s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/1], Loss: 0.0509\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"Pzzu5n8ce-0T"},"source":["Save model"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"status":"ok","timestamp":1693672281183,"user_tz":300,"elapsed":1722,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"id":"7RAwpSG2e-0T"},"outputs":[],"source":["torch.save(model.state_dict(), 'models/cat/vanilla_upvote_ratio_model.pth')"]},{"cell_type":"code","source":["# Validate on test set\n","model.eval()\n","\n","all_predictions = []\n","\n","for images, targets in tqdm(test_loader):\n","    with torch.no_grad():\n","        images = images.to(device)  # Move test images to GPU if available\n","        outputs = model(images)\n","        batch_predictions = outputs.squeeze(dim=1).cpu().numpy()  # Convert to NumPy array\n","        all_predictions.extend(batch_predictions.tolist())\n","\n","\n","test['y_pred'] = np.array(all_predictions)\n","\n","print(f\"RMSE: {np.sqrt(np.mean((test.y_pred - test.upvote_ratio)**2))}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pb3Sp5DFb5E2","executionInfo":{"status":"ok","timestamp":1693672138087,"user_tz":300,"elapsed":2,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}},"outputId":"3c8863c6-16f5-4a84-ce4c-237315e3dc24"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["RMSE: 0.20316930251549695\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1ZUsZ6qsbUS","executionInfo":{"status":"aborted","timestamp":1693589113482,"user_tz":300,"elapsed":2,"user":{"displayName":"Ian Douglas","userId":"15027398629126202839"}}},"outputs":[],"source":["# Try: predict number of comments (or comments / num_subscribers).\n","# The former is correlated .45 with score, but not correlated with year.\n","# Note that year is correlated with num subscribers.\n","# After predicting num comments, a second model can predict score, or\n","# the NN can predict score / num_comments.\n","# The second model can also be an NLP model, or accont for other tabular data.\n","\n","# And add early stopping"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}